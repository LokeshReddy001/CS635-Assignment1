{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-14T08:07:30.944917Z","iopub.status.busy":"2024-09-14T08:07:30.944587Z","iopub.status.idle":"2024-09-14T08:07:31.305501Z","shell.execute_reply":"2024-09-14T08:07:31.304523Z","shell.execute_reply.started":"2024-09-14T08:07:30.944882Z"},"trusted":true},"outputs":[],"source":["import json\n","import pandas as pd # type: ignore\n","import random"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:09:29.169541Z","iopub.status.busy":"2024-09-14T08:09:29.168529Z","iopub.status.idle":"2024-09-14T08:10:12.752769Z","shell.execute_reply":"2024-09-14T08:10:12.751645Z","shell.execute_reply.started":"2024-09-14T08:09:29.169498Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48a6915a4d594223b620eddf2c6f69fe","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d4794f938aa406aa18af1d84e99efd1","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76c1723a0a93450e9fc3d02bdf0a14c1","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"416405dfbfde41e0952f586c06c16d99","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41ff6be22dc94948a275070ef485edbe","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0eef408e145e483e8b89f4e92f1dfe6a","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e45dc59c4bab4d33ac72968974e27c00","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/298M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eec5f6c6c1fd4ab8bb0e412e4327773b","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/97.6M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7abeae0f4164f1c9b0f8dbd5bac2e03","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64b8eea05d63426cbc7b899f642d4bf6","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/241k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30bbac356fe34f23b2ffa4c27b30783b","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/58622 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56c367f22bef4c7491c36c1e61b856cc","version_major":2,"version_minor":0},"text/plain":["Generating dev split:   0%|          | 0/6489 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe95781e613743b8919bf635ccf10bc9","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/3610 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","import pandas as pd\n","train_dataset = load_dataset(\"Tevatron/wikipedia-nq\", split='dev')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:10:23.897088Z","iopub.status.busy":"2024-09-14T08:10:23.896355Z","iopub.status.idle":"2024-09-14T08:10:26.185857Z","shell.execute_reply":"2024-09-14T08:10:26.184702Z","shell.execute_reply.started":"2024-09-14T08:10:23.897042Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>query</th>\n","      <th>answers</th>\n","      <th>positive_passages</th>\n","      <th>negative_passages</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>who sings does he love me with reba</td>\n","      <td>[Linda Davis]</td>\n","      <td>[{'docid': '11828866', 'text': 'Does He Love Y...</td>\n","      <td>[{'docid': '14525568', 'text': 'song. Accordin...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>where do the great lakes meet the ocean</td>\n","      <td>[the Saint Lawrence River]</td>\n","      <td>[{'docid': '151960', 'text': 'Great Lakes The ...</td>\n","      <td>[{'docid': '8204739', 'text': 'open lakes are ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>when does the new my hero academia movie come out</td>\n","      <td>[July 5 , 2018]</td>\n","      <td>[{'docid': '20766125', 'text': 'would be joini...</td>\n","      <td>[{'docid': '20766129', 'text': 'The \"Plus Ultr...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>who was the creator of victoria 's secret</td>\n","      <td>[Roy Raymond]</td>\n","      <td>[{'docid': '13258931', 'text': 'the show.\" Vic...</td>\n","      <td>[{'docid': '16623292', 'text': 'The Time of Ou...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>when did wesley leave last of the summer wine</td>\n","      <td>[2002]</td>\n","      <td>[{'docid': '4441861', 'text': 'made his debut ...</td>\n","      <td>[{'docid': '808428', 'text': 'to Barry (Mike G...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  query_id                                              query  \\\n","0        0                who sings does he love me with reba   \n","1        1            where do the great lakes meet the ocean   \n","2        2  when does the new my hero academia movie come out   \n","3        3          who was the creator of victoria 's secret   \n","4        4      when did wesley leave last of the summer wine   \n","\n","                      answers  \\\n","0               [Linda Davis]   \n","1  [the Saint Lawrence River]   \n","2             [July 5 , 2018]   \n","3               [Roy Raymond]   \n","4                      [2002]   \n","\n","                                   positive_passages  \\\n","0  [{'docid': '11828866', 'text': 'Does He Love Y...   \n","1  [{'docid': '151960', 'text': 'Great Lakes The ...   \n","2  [{'docid': '20766125', 'text': 'would be joini...   \n","3  [{'docid': '13258931', 'text': 'the show.\" Vic...   \n","4  [{'docid': '4441861', 'text': 'made his debut ...   \n","\n","                                   negative_passages  \n","0  [{'docid': '14525568', 'text': 'song. Accordin...  \n","1  [{'docid': '8204739', 'text': 'open lakes are ...  \n","2  [{'docid': '20766129', 'text': 'The \"Plus Ultr...  \n","3  [{'docid': '16623292', 'text': 'The Time of Ou...  \n","4  [{'docid': '808428', 'text': 'to Barry (Mike G...  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["ok_df = train_dataset.to_pandas()\n","ok_df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:32:38.857180Z","iopub.status.busy":"2024-09-14T08:32:38.856770Z","iopub.status.idle":"2024-09-14T08:32:38.861650Z","shell.execute_reply":"2024-09-14T08:32:38.860656Z","shell.execute_reply.started":"2024-09-14T08:32:38.857142Z"},"trusted":true},"outputs":[],"source":["test_data = []\n","test_doc_data = []"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:32:40.919103Z","iopub.status.busy":"2024-09-14T08:32:40.918029Z","iopub.status.idle":"2024-09-14T08:32:40.943919Z","shell.execute_reply":"2024-09-14T08:32:40.942966Z","shell.execute_reply.started":"2024-09-14T08:32:40.919061Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query</th>\n","      <th>positive_passages</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>who sings does he love me with reba</td>\n","      <td>[{'docid': '11828866', 'text': 'Does He Love Y...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>where do the great lakes meet the ocean</td>\n","      <td>[{'docid': '151960', 'text': 'Great Lakes The ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>when does the new my hero academia movie come out</td>\n","      <td>[{'docid': '20766125', 'text': 'would be joini...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>who was the creator of victoria 's secret</td>\n","      <td>[{'docid': '13258931', 'text': 'the show.\" Vic...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>when did wesley leave last of the summer wine</td>\n","      <td>[{'docid': '4441861', 'text': 'made his debut ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               query  \\\n","0                who sings does he love me with reba   \n","1            where do the great lakes meet the ocean   \n","2  when does the new my hero academia movie come out   \n","3          who was the creator of victoria 's secret   \n","4      when did wesley leave last of the summer wine   \n","\n","                                   positive_passages  \n","0  [{'docid': '11828866', 'text': 'Does He Love Y...  \n","1  [{'docid': '151960', 'text': 'Great Lakes The ...  \n","2  [{'docid': '20766125', 'text': 'would be joini...  \n","3  [{'docid': '13258931', 'text': 'the show.\" Vic...  \n","4  [{'docid': '4441861', 'text': 'made his debut ...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = ok_df[['query','positive_passages']]\n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:32:44.904804Z","iopub.status.busy":"2024-09-14T08:32:44.904424Z","iopub.status.idle":"2024-09-14T08:34:31.963892Z","shell.execute_reply":"2024-09-14T08:34:31.962742Z","shell.execute_reply.started":"2024-09-14T08:32:44.904770Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>docid</th>\n","      <th>text</th>\n","      <th>posqueries</th>\n","      <th>negqueries</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>906201</td>\n","      <td>with the other three \"Major or Grand Slam\" eve...</td>\n","      <td>[who won the men 's wimbledon championship 2016]</td>\n","      <td>[who sings does he love me with reba, where do...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4843523</td>\n","      <td>Michael Rapaport Michael David Rapaport (born ...</td>\n","      <td>[who played phoebe 's boyfriend gary on friends]</td>\n","      <td>[who sings does he love me with reba, where do...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13515445</td>\n","      <td>the Sikh Empire was Sikh (78%), Hindu (12%), M...</td>\n","      <td>[leader of sikh empire who became maharajah of...</td>\n","      <td>[who sings does he love me with reba, where do...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1613707</td>\n","      <td>efficient (lack of residue). The goal is to fi...</td>\n","      <td>[what is the difference between dysphagia and ...</td>\n","      <td>[who sings does he love me with reba, where do...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12123558</td>\n","      <td>University of Central Florida College of Engin...</td>\n","      <td>[where is the university of central florida lo...</td>\n","      <td>[who sings does he love me with reba, where do...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      docid                                               text  \\\n","0    906201  with the other three \"Major or Grand Slam\" eve...   \n","1   4843523  Michael Rapaport Michael David Rapaport (born ...   \n","2  13515445  the Sikh Empire was Sikh (78%), Hindu (12%), M...   \n","3   1613707  efficient (lack of residue). The goal is to fi...   \n","4  12123558  University of Central Florida College of Engin...   \n","\n","                                          posqueries  \\\n","0   [who won the men 's wimbledon championship 2016]   \n","1   [who played phoebe 's boyfriend gary on friends]   \n","2  [leader of sikh empire who became maharajah of...   \n","3  [what is the difference between dysphagia and ...   \n","4  [where is the university of central florida lo...   \n","\n","                                          negqueries  \n","0  [who sings does he love me with reba, where do...  \n","1  [who sings does he love me with reba, where do...  \n","2  [who sings does he love me with reba, where do...  \n","3  [who sings does he love me with reba, where do...  \n","4  [who sings does he love me with reba, where do...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from collections import defaultdict\n","# Step 1: Get all unique docids and texts across all queries\n","all_docs = {}  # Dictionary to store docid -> text\n","for passages in df['positive_passages']:\n","    for passage in passages:\n","        all_docs[passage['docid']] = passage['text']\n","\n","# Step 2: Create dictionaries to store posqueries and negqueries for each docid\n","doc_pos_queries = defaultdict(list)\n","doc_neg_queries = defaultdict(list)\n","\n","# Step 3: Process each row in the original DataFrame\n","for idx, row in df.iterrows():\n","    query = row['query']\n","    pos_docids = set()\n","\n","    # Add positive queries to corresponding docids\n","    for passage in row['positive_passages']:\n","        docid = passage['docid']\n","        doc_pos_queries[docid].append(query)\n","        pos_docids.add(docid)\n","\n","    # Any docid not in pos_docids is negative for this query\n","    for docid in all_docs:\n","        if docid not in pos_docids:\n","            doc_neg_queries[docid].append(query)\n","\n","# Step 4: Collect results into a new DataFrame\n","all_docids = set(doc_pos_queries.keys()).union(doc_neg_queries.keys())\n","new_data = {\n","    'docid': [],\n","    'text': [],\n","    'posqueries': [],\n","    'negqueries': []\n","}\n","\n","for docid in all_docids:\n","    new_data['docid'].append(docid)\n","    new_data['text'].append(all_docs.get(docid, \"\"))  # Add the text for the document\n","    new_data['posqueries'].append(doc_pos_queries.get(docid, []))\n","    new_data['negqueries'].append(doc_neg_queries.get(docid, []))\n","\n","# Step 5: Create the new DataFrame and filter out rows where either list is empty\n","new_df = pd.DataFrame(new_data)\n","new_df = new_df[(new_df['posqueries'].apply(len) > 0) & (new_df['negqueries'].apply(len) > 0)]\n","\n","new_df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:34:45.183618Z","iopub.status.busy":"2024-09-14T08:34:45.183273Z","iopub.status.idle":"2024-09-14T08:34:45.189996Z","shell.execute_reply":"2024-09-14T08:34:45.188963Z","shell.execute_reply.started":"2024-09-14T08:34:45.183587Z"},"trusted":true},"outputs":[{"data":{"text/plain":["45158"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(new_df)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:34:49.890872Z","iopub.status.busy":"2024-09-14T08:34:49.890479Z","iopub.status.idle":"2024-09-14T08:38:52.993206Z","shell.execute_reply":"2024-09-14T08:38:52.992156Z","shell.execute_reply.started":"2024-09-14T08:34:49.890835Z"},"trusted":true},"outputs":[],"source":["# Iterate over the rows of the DataFrame\n","for idx, row in new_df.iterrows():\n","    doc_text = row['text']  # Get the document text\n","    posqueries = row['posqueries']  # List of positive queries\n","    negqueries = row['negqueries']  # List of negative queries\n","    \n","    # Shuffle posqueries and negqueries\n","    random.shuffle(posqueries)\n","    random.shuffle(negqueries)\n","    \n","    # Append the document and queries to the list\n","    test_doc_data.append({\n","        'doc': doc_text,\n","        'pos_que': posqueries[:min(5, len(posqueries))],  # Correct slicing for positive queries\n","        'neg_que': negqueries[:20 - min(5, len(posqueries))]  # Correct slicing for negative queries\n","    })"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:38:57.724827Z","iopub.status.busy":"2024-09-14T08:38:57.724180Z","iopub.status.idle":"2024-09-14T08:38:57.731050Z","shell.execute_reply":"2024-09-14T08:38:57.730086Z","shell.execute_reply.started":"2024-09-14T08:38:57.724787Z"},"trusted":true},"outputs":[{"data":{"text/plain":["45158"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(test_doc_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:39:01.044257Z","iopub.status.busy":"2024-09-14T08:39:01.043434Z","iopub.status.idle":"2024-09-14T08:39:05.238782Z","shell.execute_reply":"2024-09-14T08:39:05.237785Z","shell.execute_reply.started":"2024-09-14T08:39:01.044218Z"},"trusted":true},"outputs":[],"source":["\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","import torch\n","from torch import nn\n","\n","class ContrastiveLoss(nn.Module):\n","    \"\"\"\n","        Given a list of scores s1,s2,..sn, calculates -log(e^s1/(e^s1+e^s2+...+e^sn))\n","    \"\"\"\n","    def __init__(self):\n","        super(ContrastiveLoss, self).__init__()\n","\n","    def forward(self, scores):\n","        scaled_scores = scores / 1.0\n","        max_score = torch.max(scaled_scores)\n","        stable_scaled_scores = scaled_scores - max_score\n","        log_sum_exp = max_score + torch.log(torch.sum(torch.exp(stable_scaled_scores)))\n","        loss = log_sum_exp - scaled_scores[0]\n","\n","        return loss\n","    \n","    \n","class BertClsFFN(nn.Module):\n","    \"\"\"\n","        A small feed forward network on top of CLS embedding, to get a score\n","    \"\"\"\n","    def __init__(self):\n","        super(BertClsFFN, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.ffn = nn.Sequential(\n","            nn.Linear(768, 32),\n","            nn.ReLU(),\n","            nn.LayerNorm(32),\n","            nn.Linear(32, 8),\n","            nn.ReLU(),\n","            nn.LayerNorm(8),\n","            nn.Linear(8, 1),\n","\n","        )\n","        self.freeze_bert()\n","\n","    \n","    def freeze_bert(self):\n","        self.bert.embeddings.requires_grad_(False)\n","        for param in self.bert.encoder.layer[:11].parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, input_tokens):\n","        sentence_embed = self.bert(**input_tokens).pooler_output\n","        scores = self.ffn(sentence_embed).reshape(-1)\n","        return scores\n","\n","\n","\n","class BertLogitScorer(nn.Module):\n","    \"\"\"\n","        If the input format is [CLS] `sent1` [SEP] `sent2` [SEP], we sum the log_probs of tokens of `sent2` to get a representation of a score\n","    \"\"\"\n","    def __init__(self):\n","        super(BertLogitScorer, self).__init__()\n","        self.bert = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","        self.freeze_bert()\n","\n","    def freeze_bert(self):\n","        self.bert.bert.embeddings.requires_grad_(False)\n","        for param in self.bert.bert.encoder.layer[:10].parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, input_tokens):\n","        input_ids = input_tokens['input_ids']\n","        batch_size, seq_length = input_ids.shape\n","        logits = self.bert(**input_tokens).logits\n","        log_probs = F.log_softmax(logits, dim=-1)\n","\n","        sums = torch.zeros(batch_size, device=logits.device)\n","\n","        for i in range(batch_size):\n","            sep_indices = (input_ids[i] == 102).nonzero(as_tuple=True)[0]\n","            idx1, idx2 = sep_indices[0].item(), sep_indices[1].item()\n","            token_ids_in_range = input_ids[i, idx1 + 1:idx2]\n","            log_probs_in_range = log_probs[i, idx1 + 1:idx2]\n","            gathered_log_probs = torch.gather(log_probs_in_range, dim=1, index=token_ids_in_range.unsqueeze(-1)).squeeze(-1)\n","            \n","            sums[i] = torch.sum(gathered_log_probs)\n","\n","        return sums\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:39:12.982994Z","iopub.status.busy":"2024-09-14T08:39:12.981671Z","iopub.status.idle":"2024-09-14T08:39:13.004072Z","shell.execute_reply":"2024-09-14T08:39:13.003060Z","shell.execute_reply.started":"2024-09-14T08:39:12.982940Z"},"trusted":true},"outputs":[],"source":["class DocLH_CLS(nn.Module):\n","    def __init__(self, model_path=None):\n","        super(DocLH_CLS,self).__init__()\n","        self.bert_scorer = BertClsFFN()\n","        if model_path is not None:\n","            self.bert_scorer.load_state_dict(torch.load(model_path))\n","        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    \n","    def forward(self, d):\n","        texts = []\n","        for pd in d['pos_doc']:\n","            text = d['query'] + ' [SEP] ' + pd\n","            texts.append(text)\n","        for nd in d['neg_doc']:\n","            text = d['query'] + ' [SEP] ' + nd\n","            texts.append(text)\n","        input_tokens = self.bert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to('cuda')\n","        scores = self.bert_scorer(input_tokens)\n","        return scores\n","\n","class DocLH_Logit(nn.Module):\n","    def __init__(self, model_path=None):\n","        super(DocLH_Logit,self).__init__()\n","        self.bert_scorer = BertLogitScorer()\n","        if model_path is not None:\n","            self.bert_scorer.load_state_dict(torch.load(model_path))\n","        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","    def forward(self, d):\n","        texts = []\n","        for pd in d['pos_doc']:\n","            text = d['query'] + ' [SEP] ' + pd\n","            texts.append(text)\n","        for nd in d['neg_doc']:\n","            text = d['query'] + ' [SEP] ' + nd\n","            texts.append(text)\n","        input_tokens = self.bert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to('cuda')\n","        scores = self.bert_scorer(input_tokens)\n","        return scores\n","    \n","\n","class QueryLH_CLS(nn.Module):\n","    def __init__(self, model_path=None):\n","        super(QueryLH_CLS,self).__init__()\n","        self.bert_scorer = BertClsFFN()\n","        if model_path is not None:\n","            self.bert_scorer.load_state_dict(torch.load(model_path))\n","        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    \n","    def forward(self, d):\n","        texts = []\n","        for pd in d['pos_que']:\n","            text = d['doc'] + ' [SEP] ' + pd\n","            texts.append(text)\n","        for nd in d['neg_que']:\n","            text = d['doc'] + ' [SEP] ' + nd\n","            texts.append(text)\n","        input_tokens = self.bert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to('cuda')\n","        scores = self.bert_scorer(input_tokens)\n","        return scores\n","\n","class QueryLH_Logit(nn.Module):\n","    def __init__(self, model_path=None):\n","        super(QueryLH_Logit,self).__init__()\n","        self.bert_scorer = BertLogitScorer()\n","        if model_path is not None:\n","            self.bert_scorer.load_state_dict(torch.load(model_path))\n","        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    \n","    def forward(self, d):\n","        texts = []\n","        for pd in d['pos_que']:\n","            text = d['doc'] + ' [SEP] ' + pd\n","            texts.append(text)\n","        for nd in d['neg_que']:\n","            text = d['doc'] + ' [SEP] ' + nd\n","            texts.append(text)\n","        input_tokens = self.bert_tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to('cuda')\n","        scores = self.bert_scorer(input_tokens)\n","        return scores"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:39:24.172730Z","iopub.status.busy":"2024-09-14T08:39:24.172013Z","iopub.status.idle":"2024-09-14T08:39:35.231621Z","shell.execute_reply":"2024-09-14T08:39:35.230640Z","shell.execute_reply.started":"2024-09-14T08:39:24.172677Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65f13bde0a9a41838f1598a28b47b065","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7956d8da5664f8aa994a309754c2f2a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/tmp/ipykernel_36/269213134.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.bert_scorer.load_state_dict(torch.load(model_path))\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcb92aaba0734b7195fd3846f161da2f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af8ab54d1e8e47f4b4e31d8fd075daa6","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30923912a1d349fd9fcedb65598dafd5","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","/tmp/ipykernel_36/269213134.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.bert_scorer.load_state_dict(torch.load(model_path))\n"]}],"source":["model_Doc_log = DocLH_Logit(model_path = '/kaggle/input/wiki_doclh_logit/transformers/default/1/model_checkpoints/wiki_DocLH_Logits_epoch2.pth').to('cuda')\n","model_Doc_cls = DocLH_CLS(model_path = '/kaggle/input/wiki_doclh_cls/transformers/default/1/model_checkpoints/wiki_wiki_DocLH_CLS_epoch2.pth').to('cuda')\n","model_que_log = QueryLH_Logit(model_path = '/kaggle/input/query_cls_logits_wiki/transformers/default/1/model_checkpoints/wiki_QueryLH_Logits_epoch1.pth').to('cuda')\n","model_que_cls = QueryLH_CLS(model_path = '/kaggle/input/query_cls_logits_wiki/transformers/default/1/model_checkpoints/wiki_QueryLH_CLS_epoch1.pth').to('cuda')\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:39:43.651838Z","iopub.status.busy":"2024-09-14T08:39:43.651355Z","iopub.status.idle":"2024-09-14T08:39:43.661749Z","shell.execute_reply":"2024-09-14T08:39:43.660735Z","shell.execute_reply.started":"2024-09-14T08:39:43.651790Z"},"trusted":true},"outputs":[],"source":["def prec(scores,k,gd):\n","    count = 0\n","    for i in range(k):\n","        count = count + scores[i][1]\n","    return float(count/k),float(min(k,gd)/k)\n","\n","def mrr(scores):\n","    for i in range(len(scores)):\n","        if scores[i][1] == 1:\n","            return float(1.0/float(i+1))\n","        \n","def map_(scores,gd):\n","    sum = 0\n","    temp = 0\n","    for i in range(len(scores)):\n","        if scores[i][1] == 1:\n","            temp = temp + 1\n","            sum = sum + float((1.0*temp)/float(i+1))\n","            \n","    return float(sum/gd)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T16:56:12.641840Z","iopub.status.busy":"2024-09-11T16:56:12.640934Z","iopub.status.idle":"2024-09-11T16:56:12.649943Z","shell.execute_reply":"2024-09-11T16:56:12.648962Z","shell.execute_reply.started":"2024-09-11T16:56:12.641797Z"},"trusted":true},"outputs":[],"source":["model_names = ['DocLH_Logit','DocLH_CLS']\n","models = [model_Doc_log, model_Doc_cls]\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:40:38.870743Z","iopub.status.busy":"2024-09-14T08:40:38.870329Z","iopub.status.idle":"2024-09-14T08:40:38.877499Z","shell.execute_reply":"2024-09-14T08:40:38.876424Z","shell.execute_reply.started":"2024-09-14T08:40:38.870692Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","eval_scores = []\n","for mo in range(2):\n","    mo_name = model_names[mo]\n","    model = models[mo]\n","    prec1 = 0.0\n","    prec10 = 0.0\n","    max_prec1 = 0.0\n","    max_prec10 = 0.0\n","    mrr_= 0.0\n","    map__ = 0.0\n","    for test_d in tqdm(test_data, desc=\"Processing\"):\n","        gold_d = []\n","        gold_d.extend([1] * len(test_d['pos_doc']))\n","        gold_d.extend([0] * len(test_d['neg_doc']))\n","\n","        scores = model(test_d)\n","        scores = scores.tolist()\n","        my_pairs = [(scores[i],gold_d[i]) for i in range(len(scores))]\n","        my_pairs = sorted(my_pairs, key=lambda x: x[0], reverse=True)\n","        prec1 += prec(my_pairs,1,len(test_d['pos_doc']))[0]\n","        max_prec1 += prec(my_pairs,1,len(test_d['pos_doc']))[1]\n","        prec10 += prec(my_pairs,10,len(test_d['pos_doc']))[0]\n","        max_prec10 += prec(my_pairs,10,len(test_d['pos_doc']))[1]\n","        mrr_ += mrr(my_pairs)\n","        map__ += map_(my_pairs,len(test_d['pos_doc']))\n","        \n","    scores_data = {}\n","    scores_data['model_name'] = mo_name\n","    scores_data['prec1'] = float(prec1/len(test_data))\n","    scores_data['prec10'] =float(prec10/len(test_data))\n","    scores_data['mrr'] = float(mrr_/len(test_data))\n","    scores_data['map'] = float(map__/len(test_data))\n","    scores_data['max_prec1'] = float(max_prec1/len(test_data))\n","    scores_data['max_prec10'] = float(max_prec10/len(test_data))\n","    \n","    print(scores_data)\n","    \n","    eval_scores.append(scores_data)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# print(eval_scores)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:40:42.153640Z","iopub.status.busy":"2024-09-14T08:40:42.152958Z","iopub.status.idle":"2024-09-14T08:40:42.157820Z","shell.execute_reply":"2024-09-14T08:40:42.156776Z","shell.execute_reply.started":"2024-09-14T08:40:42.153597Z"},"trusted":true},"outputs":[],"source":["model_names = ['QueryLH_Logit','QueryLH_CLS']\n","models = [model_que_log,model_que_cls]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-14T08:40:46.222774Z","iopub.status.busy":"2024-09-14T08:40:46.221770Z","iopub.status.idle":"2024-09-14T08:40:47.631042Z","shell.execute_reply":"2024-09-14T08:40:47.630053Z","shell.execute_reply.started":"2024-09-14T08:40:46.222701Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","for mo in range(2):\n","    mo_name = model_names[mo]\n","    model = models[mo]\n","    prec1 = 0.0\n","    prec10 = 0.0\n","    max_prec1 = 0.0\n","    max_prec10 = 0.0\n","    mrr_= 0.0\n","    map__ = 0.0\n","    total = 0\n","    for test_d in tqdm(test_doc_data, desc=\"Processing\"):\n","        try:\n","            gold_d = []\n","            gold_d.extend([1] * len(test_d['pos_que']))\n","            gold_d.extend([0] * len(test_d['neg_que']))\n","\n","            scores = model(test_d)\n","            scores = scores.tolist()\n","            my_pairs = [(scores[i],gold_d[i]) for i in range(len(gold_d))]\n","            my_pairs = sorted(my_pairs, key=lambda x: x[0], reverse=True)\n","            prec1 += prec(my_pairs,1,len(test_d['pos_que']))[0]\n","            max_prec1 += prec(my_pairs,1,len(test_d['pos_que']))[1]\n","            prec10 += prec(my_pairs,10,len(test_d['pos_que']))[0]\n","            max_prec10 += prec(my_pairs,10,len(test_d['pos_que']))[1]\n","            mrr_ += mrr(my_pairs)\n","            map__ += map_(my_pairs,len(test_d['pos_que']))\n","            total+=1\n","        except:\n","            pass\n","        \n","        \n","    scores_data = {}\n","    scores_data['model_name'] = mo_name\n","    scores_data['prec1'] = float(prec1/total)\n","    scores_data['prec10'] =float(prec10/total)\n","    scores_data['mrr'] = float(mrr_/total)\n","    scores_data['map'] = float(map__/total)\n","    scores_data['max_prec1'] = float(max_prec1/total)\n","    scores_data['max_prec10'] = float(max_prec10/total)\n","    \n","    print(scores_data)\n","    \n","    eval_scores.append(scores_data)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T17:03:03.399263Z","iopub.status.busy":"2024-09-11T17:03:03.398552Z","iopub.status.idle":"2024-09-11T17:03:03.406213Z","shell.execute_reply":"2024-09-11T17:03:03.405190Z","shell.execute_reply.started":"2024-09-11T17:03:03.399217Z"},"trusted":true},"outputs":[],"source":["print(eval_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","with open('evaluate.json', 'w') as f:\n","    json.dump(eval_scores, f, indent=4)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"isSourceIdPinned":true,"modelId":119246,"modelInstanceId":95043,"sourceId":113287,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":119238,"modelInstanceId":95035,"sourceId":113277,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":119239,"modelInstanceId":95036,"sourceId":113278,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
